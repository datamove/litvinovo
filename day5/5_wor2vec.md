# Natural Language processing

## word2vec - обучение модели

Скачайте в домашнюю директорию Jupyter тетрадку `word2vec-train.ipynb` и файл `anna-karenina.txt`.

Запустите тетрадку. Перед исполнением ячеек, сделайте новую и там установите пакет gensim.

`!pip install gensim`

Запустите другие ячейки.

Поиграйте с синонимами слов, со "сложением" и "вычитанием".

## Генерация текста

Откройте в колабе:

### ruGPT-3 маленькая модель

https://colab.research.google.com/github/ai-forever/ru-gpts/blob/master/examples/Generate_text_with_RuGPTs_HF.ipynb

### ruGPT-3 XL

https://colab.research.google.com/github/ai-forever/ru-gpts/blob/master/examples/ruGPT3XL_generation.ipynb

### ruGPT-3 c подстройками

https://colab.research.google.com/github/ai-forever/ru-gpts/blob/master/examples/ruGPT3XL_finetune_example.ipynb

### Больше примеров

https://github.com/ai-forever


